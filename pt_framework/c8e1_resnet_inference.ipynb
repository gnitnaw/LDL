{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnitnaw/LDL/blob/main/pt_framework/c8e1_resnet_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u-t6pexkvu2n",
        "outputId": "bd683383-2ad3-4ddf-e2be-e62a5eae5f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe MIT License (MIT)\\nCopyright (c) 2021 NVIDIA\\nPermission is hereby granted, free of charge, to any person obtaining a copy of\\nthis software and associated documentation files (the \"Software\"), to deal in\\nthe Software without restriction, including without limitation the rights to\\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\\nthe Software, and to permit persons to whom the Software is furnished to do so,\\nsubject to the following conditions:\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "The MIT License (MIT)\n",
        "Copyright (c) 2021 NVIDIA\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
        "this software and associated documentation files (the \"Software\"), to deal in\n",
        "the Software without restriction, including without limitation the rights to\n",
        "use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
        "the Software, and to permit persons to whom the Software is furnished to do so,\n",
        "subject to the following conditions:\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
        "FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
        "COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
        "IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
        "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnAYuzDWvu2p"
      },
      "source": [
        "This code example demonstrates how to use a pre-trained residual network to solve an image classification problem, using a picture of a dog. More context for this code example can be found in the section \"Programming Example: Use a Pretrained ResNet Implementation\" in Chapter 8 in the book Learning Deep Learning by Magnus Ekman (ISBN: 9780137470358).\n",
        "\n",
        "We start with a number of import statements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5mA8saF1vu2r",
        "outputId": "dcdb2e87-4e0d-47d1-e7f3-77f5a3d2260e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_head = '/content/drive/MyDrive/Colab Notebooks/' # You have to change this. \n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPV6fgTkvu2s"
      },
      "source": [
        "In the next code snippet we load the image and transform it to be suitable to feed into the pretrained network. The transformation involves normalizing, converting to tensor, and resizing. The parameters used in the normalization steps are the mean and standard deviation for each color channel from the training dataset that was used to train the pretrained model. These values are documented on pytorch.org.\n",
        "\n",
        "Finally, since the network expects an array of multiple images, so we add a fourth dimension using the unsqueeze() method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1r0j1EkKvu2t"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess image.\n",
        "DOG_FILENAME = path_head+'data/dog.jpg'\n",
        "CAT_FILENAME = path_head+'data/cat.jpg'\n",
        "\n",
        "image = Image.open(DOG_FILENAME)\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "]) # Parameters are documented at pytorch.org.\n",
        "input_tensor = preprocess(image)\n",
        "\n",
        "# Convert to 4-dimensional tensor.\n",
        "inputs = input_tensor.unsqueeze(0)\n",
        "\n",
        "image_cat = Image.open(CAT_FILENAME)\n",
        "input_tensor_cat = preprocess(image_cat)\n",
        "inputs_cat = input_tensor_cat.unsqueeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzEy1oOgvu2u"
      },
      "source": [
        "The final code snippet starts with loading the pretrained ResNet-50 model. We put the model in evaluation mode since we will use it for inference and not training. We then move the model and the input image to the GPU (if present).\n",
        "\n",
        "We then do a prediction by calling the model with the image as input. By doing the call to a model inside the scope of a torch.no_grad() statement, PyTorch is told that it does not need to track information needed to automatically be able to calculate gradients for the model during this call. This reduces the amount of computation needed and makes the code snippet run faster. In this case when we only do a single call to the model it is not that important, but it can make a difference when doing inference for a large number of images.\n",
        "\n",
        "As we have previously seen, when implementing a model in PyTorch, the activation function for the final SoftMax layer is omitted since it is included in the PyTorch implementation of the cross-entropy loss function. However, that is only the case when using a model for training. When using a model for inference, we therefore need to run the outputs through a softmax function to convert the logits (weighted sums) to probabilities. This is done with a call to torch.nn.functiona.softmax().\n",
        "\n",
        "We sort the resulting probabilities with a call to torch.sort() which returns both the sorted values and the indices of their locations in the vector. We are interested in the indices (each index corresponds to an image category). We then print out the indices of the top five image categories, as well as their corresponding probabilities. The calls to item() converts the values from the PyTorch tensor datatype to a standard Python datatype.\n",
        "\n",
        "This program prints out only the class ID, and not the class names. To also print the class name you would need to add code to convert from class ID to class name using a look-up table. The mapping between class ID and class name is available for download in various formats from various sources. One good format is found here:\n",
        "https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZB7uWgGavu2u",
        "outputId": "13b8ddb2-63a6-48e4-b963-940fc820c889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258,
          "referenced_widgets": [
            "d2cdce9219504b228159483d974f0baf",
            "54793212da164649a72c497343059f46",
            "7c51a0da73f44cdb8150da0f1e861a8f",
            "503fe82a55d341049780299cfbcd05ca",
            "defb788e013c4653920b50ed12b8764d",
            "8760f2463b9d400998c0d1f216e89582",
            "d40aa32288374a5aa5717697d9147d8d",
            "ecc29c68b8ad44f68136d72909315593",
            "7a83a08fc2334446bee2292df2600439",
            "b92d7ffbbe70434e9d8156ec4550cefd",
            "7dd79bf1d3d24c949e8ea7de1abc3502"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2cdce9219504b228159483d974f0baf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImageNet class: 248 , probability = 0.167\n",
            "ImageNet class: 250 , probability = 0.149\n",
            "ImageNet class: 797 , probability = 0.112\n",
            "ImageNet class: 151 , probability = 0.111\n",
            "ImageNet class: 172 , probability = 0.080\n"
          ]
        }
      ],
      "source": [
        "# Load the pre-trained model.\n",
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Transfer model to GPU.\n",
        "model.to(device)\n",
        "\n",
        "# Do prediction.\n",
        "inputs = inputs.to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "\n",
        "# Convert to probabilities, since final SoftMax activation is not in pretrained model.\n",
        "probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
        "\n",
        "# Print class ID for top 5 predictions.\n",
        "_, indices = torch.sort(probabilities, descending=True)\n",
        "for i in range(0, 5):\n",
        "    print('ImageNet class:', indices[i].item(), ', probability = %4.3f' % probabilities[indices[i]].item())\n",
        "\n",
        "# Show image.\n",
        "image.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do prediction.\n",
        "inputs_cat = inputs_cat.to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(inputs_cat)\n",
        "\n",
        "# Convert to probabilities, since final SoftMax activation is not in pretrained model.\n",
        "probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
        "\n",
        "# Print class ID for top 5 predictions.\n",
        "_, indices = torch.sort(probabilities, descending=True)\n",
        "for i in range(0, 5):\n",
        "    print('ImageNet class:', indices[i].item(), ', probability = %4.3f' % probabilities[indices[i]].item())\n",
        "\n",
        "# Show image.\n",
        "image_cat.show()\n"
      ],
      "metadata": {
        "id": "pki9Mt7AwKjV",
        "outputId": "637ccc41-0179-4d87-8ce6-8ceee0a72c7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImageNet class: 281 , probability = 0.421\n",
            "ImageNet class: 282 , probability = 0.142\n",
            "ImageNet class: 285 , probability = 0.138\n",
            "ImageNet class: 782 , probability = 0.025\n",
            "ImageNet class: 526 , probability = 0.025\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d2cdce9219504b228159483d974f0baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54793212da164649a72c497343059f46",
              "IPY_MODEL_7c51a0da73f44cdb8150da0f1e861a8f",
              "IPY_MODEL_503fe82a55d341049780299cfbcd05ca"
            ],
            "layout": "IPY_MODEL_defb788e013c4653920b50ed12b8764d"
          }
        },
        "54793212da164649a72c497343059f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8760f2463b9d400998c0d1f216e89582",
            "placeholder": "​",
            "style": "IPY_MODEL_d40aa32288374a5aa5717697d9147d8d",
            "value": "100%"
          }
        },
        "7c51a0da73f44cdb8150da0f1e861a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecc29c68b8ad44f68136d72909315593",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a83a08fc2334446bee2292df2600439",
            "value": 102530333
          }
        },
        "503fe82a55d341049780299cfbcd05ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b92d7ffbbe70434e9d8156ec4550cefd",
            "placeholder": "​",
            "style": "IPY_MODEL_7dd79bf1d3d24c949e8ea7de1abc3502",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 227MB/s]"
          }
        },
        "defb788e013c4653920b50ed12b8764d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8760f2463b9d400998c0d1f216e89582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d40aa32288374a5aa5717697d9147d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecc29c68b8ad44f68136d72909315593": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a83a08fc2334446bee2292df2600439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b92d7ffbbe70434e9d8156ec4550cefd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd79bf1d3d24c949e8ea7de1abc3502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}