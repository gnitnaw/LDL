{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnitnaw/LDL/blob/main/tf_framework/c5e2_mnist_learning_conf5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R5xOk3UPSKiN",
        "outputId": "2ec8c305-8732-4c5e-b32b-ef93aba52b57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe MIT License (MIT)\\nCopyright (c) 2021 NVIDIA\\nPermission is hereby granted, free of charge, to any person obtaining a copy of\\nthis software and associated documentation files (the \"Software\"), to deal in\\nthe Software without restriction, including without limitation the rights to\\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\\nthe Software, and to permit persons to whom the Software is furnished to do so,\\nsubject to the following conditions:\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "The MIT License (MIT)\n",
        "Copyright (c) 2021 NVIDIA\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
        "this software and associated documentation files (the \"Software\"), to deal in\n",
        "the Software without restriction, including without limitation the rights to\n",
        "use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
        "the Software, and to permit persons to whom the Software is furnished to do so,\n",
        "subject to the following conditions:\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
        "FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
        "COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
        "IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
        "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FImk6CI2SKiP"
      },
      "source": [
        "This code example is very similar to c5e1_mnist_learning but the network is modified to use ReLU neruons in the hidden layer, softmax in the output layer, categorical crossentropy as loss function, Adam as optimizer, and a mini-batch size of 64. More context for this code example can be found in the section \"Experiment: Tweaking Network and Learning Parameters\" in Chapter 5 in the book Learning Deep Learning by Magnus Ekman (ISBN: 9780137470358)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JW6rPYR6SKiR",
        "outputId": "f2484953-8694-44ca-9b72-95028db14813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "938/938 - 5s - loss: 0.3611 - accuracy: 0.8899 - val_loss: 0.2122 - val_accuracy: 0.9373 - 5s/epoch - 5ms/step\n",
            "Epoch 2/20\n",
            "938/938 - 4s - loss: 0.1864 - accuracy: 0.9459 - val_loss: 0.1677 - val_accuracy: 0.9483 - 4s/epoch - 4ms/step\n",
            "Epoch 3/20\n",
            "938/938 - 3s - loss: 0.1521 - accuracy: 0.9550 - val_loss: 0.1451 - val_accuracy: 0.9568 - 3s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "938/938 - 3s - loss: 0.1318 - accuracy: 0.9609 - val_loss: 0.1437 - val_accuracy: 0.9571 - 3s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "938/938 - 2s - loss: 0.1177 - accuracy: 0.9641 - val_loss: 0.1291 - val_accuracy: 0.9621 - 2s/epoch - 2ms/step\n",
            "Epoch 6/20\n",
            "938/938 - 2s - loss: 0.1090 - accuracy: 0.9671 - val_loss: 0.1282 - val_accuracy: 0.9629 - 2s/epoch - 2ms/step\n",
            "Epoch 7/20\n",
            "938/938 - 2s - loss: 0.1007 - accuracy: 0.9694 - val_loss: 0.1330 - val_accuracy: 0.9624 - 2s/epoch - 2ms/step\n",
            "Epoch 8/20\n",
            "938/938 - 2s - loss: 0.0935 - accuracy: 0.9716 - val_loss: 0.1275 - val_accuracy: 0.9625 - 2s/epoch - 2ms/step\n",
            "Epoch 9/20\n",
            "938/938 - 2s - loss: 0.0887 - accuracy: 0.9722 - val_loss: 0.1269 - val_accuracy: 0.9646 - 2s/epoch - 2ms/step\n",
            "Epoch 10/20\n",
            "938/938 - 2s - loss: 0.0838 - accuracy: 0.9747 - val_loss: 0.1277 - val_accuracy: 0.9640 - 2s/epoch - 2ms/step\n",
            "Epoch 11/20\n",
            "938/938 - 2s - loss: 0.0797 - accuracy: 0.9751 - val_loss: 0.1315 - val_accuracy: 0.9627 - 2s/epoch - 2ms/step\n",
            "Epoch 12/20\n",
            "938/938 - 2s - loss: 0.0769 - accuracy: 0.9761 - val_loss: 0.1204 - val_accuracy: 0.9658 - 2s/epoch - 2ms/step\n",
            "Epoch 13/20\n",
            "938/938 - 2s - loss: 0.0735 - accuracy: 0.9773 - val_loss: 0.1272 - val_accuracy: 0.9661 - 2s/epoch - 2ms/step\n",
            "Epoch 14/20\n",
            "938/938 - 2s - loss: 0.0696 - accuracy: 0.9781 - val_loss: 0.1327 - val_accuracy: 0.9646 - 2s/epoch - 2ms/step\n",
            "Epoch 15/20\n",
            "938/938 - 2s - loss: 0.0674 - accuracy: 0.9788 - val_loss: 0.1342 - val_accuracy: 0.9656 - 2s/epoch - 2ms/step\n",
            "Epoch 16/20\n",
            "938/938 - 2s - loss: 0.0649 - accuracy: 0.9799 - val_loss: 0.1264 - val_accuracy: 0.9666 - 2s/epoch - 2ms/step\n",
            "Epoch 17/20\n",
            "938/938 - 2s - loss: 0.0615 - accuracy: 0.9801 - val_loss: 0.1206 - val_accuracy: 0.9679 - 2s/epoch - 2ms/step\n",
            "Epoch 18/20\n",
            "938/938 - 2s - loss: 0.0614 - accuracy: 0.9803 - val_loss: 0.1322 - val_accuracy: 0.9663 - 2s/epoch - 2ms/step\n",
            "Epoch 19/20\n",
            "938/938 - 2s - loss: 0.0571 - accuracy: 0.9818 - val_loss: 0.1304 - val_accuracy: 0.9673 - 2s/epoch - 2ms/step\n",
            "Epoch 20/20\n",
            "938/938 - 2s - loss: 0.0563 - accuracy: 0.9819 - val_loss: 0.1428 - val_accuracy: 0.9625 - 2s/epoch - 2ms/step\n",
            "================================ Conf. 1 ================================ \n",
            "Epoch 1/20\n",
            "60000/60000 - 117s - loss: 0.2607 - accuracy: 0.9368 - val_loss: 0.1858 - val_accuracy: 0.9531 - 117s/epoch - 2ms/step\n",
            "Epoch 2/20\n",
            "60000/60000 - 123s - loss: 0.2104 - accuracy: 0.9471 - val_loss: 0.1977 - val_accuracy: 0.9521 - 123s/epoch - 2ms/step\n",
            "Epoch 3/20\n",
            "60000/60000 - 116s - loss: 0.1914 - accuracy: 0.9520 - val_loss: 0.2948 - val_accuracy: 0.9339 - 116s/epoch - 2ms/step\n",
            "Epoch 4/20\n",
            "60000/60000 - 116s - loss: 0.1854 - accuracy: 0.9542 - val_loss: 0.2308 - val_accuracy: 0.9526 - 116s/epoch - 2ms/step\n",
            "Epoch 5/20\n",
            "60000/60000 - 124s - loss: 0.1762 - accuracy: 0.9573 - val_loss: 0.2692 - val_accuracy: 0.9473 - 124s/epoch - 2ms/step\n",
            "Epoch 6/20\n",
            "60000/60000 - 116s - loss: 0.1684 - accuracy: 0.9591 - val_loss: 0.2350 - val_accuracy: 0.9496 - 116s/epoch - 2ms/step\n",
            "Epoch 7/20\n",
            "60000/60000 - 115s - loss: 0.1626 - accuracy: 0.9607 - val_loss: 0.2051 - val_accuracy: 0.9580 - 115s/epoch - 2ms/step\n",
            "Epoch 8/20\n",
            "60000/60000 - 116s - loss: 0.1655 - accuracy: 0.9615 - val_loss: 0.2153 - val_accuracy: 0.9562 - 116s/epoch - 2ms/step\n",
            "Epoch 9/20\n",
            "60000/60000 - 122s - loss: 0.1588 - accuracy: 0.9620 - val_loss: 0.2674 - val_accuracy: 0.9536 - 122s/epoch - 2ms/step\n",
            "Epoch 10/20\n",
            "60000/60000 - 121s - loss: 0.1582 - accuracy: 0.9638 - val_loss: 0.2834 - val_accuracy: 0.9518 - 121s/epoch - 2ms/step\n",
            "Epoch 11/20\n",
            "60000/60000 - 121s - loss: 0.1535 - accuracy: 0.9646 - val_loss: 0.2344 - val_accuracy: 0.9592 - 121s/epoch - 2ms/step\n",
            "Epoch 12/20\n",
            "60000/60000 - 120s - loss: 0.1531 - accuracy: 0.9648 - val_loss: 0.2715 - val_accuracy: 0.9525 - 120s/epoch - 2ms/step\n",
            "Epoch 13/20\n",
            "60000/60000 - 124s - loss: 0.1517 - accuracy: 0.9665 - val_loss: 0.2700 - val_accuracy: 0.9593 - 124s/epoch - 2ms/step\n",
            "Epoch 14/20\n",
            "60000/60000 - 117s - loss: 0.1552 - accuracy: 0.9655 - val_loss: 0.2901 - val_accuracy: 0.9533 - 117s/epoch - 2ms/step\n",
            "Epoch 15/20\n",
            "60000/60000 - 116s - loss: 0.1530 - accuracy: 0.9672 - val_loss: 0.3161 - val_accuracy: 0.9492 - 116s/epoch - 2ms/step\n",
            "Epoch 16/20\n",
            "60000/60000 - 118s - loss: 0.1506 - accuracy: 0.9673 - val_loss: 0.3223 - val_accuracy: 0.9546 - 118s/epoch - 2ms/step\n",
            "Epoch 17/20\n",
            "60000/60000 - 119s - loss: 0.1476 - accuracy: 0.9674 - val_loss: 0.2849 - val_accuracy: 0.9597 - 119s/epoch - 2ms/step\n",
            "Epoch 18/20\n",
            "60000/60000 - 134s - loss: 0.1480 - accuracy: 0.9680 - val_loss: 0.3054 - val_accuracy: 0.9538 - 134s/epoch - 2ms/step\n",
            "Epoch 19/20\n",
            "60000/60000 - 130s - loss: 0.1431 - accuracy: 0.9683 - val_loss: 0.3298 - val_accuracy: 0.9571 - 130s/epoch - 2ms/step\n",
            "Epoch 20/20\n",
            "60000/60000 - 135s - loss: 0.1460 - accuracy: 0.9695 - val_loss: 0.3075 - val_accuracy: 0.9569 - 135s/epoch - 2ms/step\n",
            "================================ Conf. 2 ================================ \n",
            "Epoch 1/20\n",
            "60000/60000 - 133s - loss: 0.1439 - accuracy: 0.9700 - val_loss: 0.3121 - val_accuracy: 0.9546 - 133s/epoch - 2ms/step\n",
            "Epoch 2/20\n",
            "60000/60000 - 116s - loss: 0.1429 - accuracy: 0.9701 - val_loss: 0.4273 - val_accuracy: 0.9488 - 116s/epoch - 2ms/step\n",
            "Epoch 3/20\n",
            "60000/60000 - 129s - loss: 0.1442 - accuracy: 0.9704 - val_loss: 0.3736 - val_accuracy: 0.9555 - 129s/epoch - 2ms/step\n",
            "Epoch 4/20\n",
            "60000/60000 - 141s - loss: 0.1461 - accuracy: 0.9702 - val_loss: 0.3822 - val_accuracy: 0.9519 - 141s/epoch - 2ms/step\n",
            "Epoch 5/20\n",
            "60000/60000 - 115s - loss: 0.1470 - accuracy: 0.9699 - val_loss: 0.4087 - val_accuracy: 0.9548 - 115s/epoch - 2ms/step\n",
            "Epoch 6/20\n",
            "60000/60000 - 113s - loss: 0.1390 - accuracy: 0.9722 - val_loss: 0.4045 - val_accuracy: 0.9564 - 113s/epoch - 2ms/step\n",
            "Epoch 7/20\n",
            "60000/60000 - 120s - loss: 0.1390 - accuracy: 0.9714 - val_loss: 0.3586 - val_accuracy: 0.9591 - 120s/epoch - 2ms/step\n",
            "Epoch 8/20\n",
            "60000/60000 - 121s - loss: 0.1362 - accuracy: 0.9727 - val_loss: 0.4102 - val_accuracy: 0.9553 - 121s/epoch - 2ms/step\n",
            "Epoch 9/20\n",
            "60000/60000 - 113s - loss: 0.1388 - accuracy: 0.9726 - val_loss: 0.4015 - val_accuracy: 0.9535 - 113s/epoch - 2ms/step\n",
            "Epoch 10/20\n",
            "60000/60000 - 120s - loss: 0.1358 - accuracy: 0.9725 - val_loss: 0.5054 - val_accuracy: 0.9520 - 120s/epoch - 2ms/step\n",
            "Epoch 11/20\n",
            "60000/60000 - 115s - loss: 0.1368 - accuracy: 0.9729 - val_loss: 0.4629 - val_accuracy: 0.9487 - 115s/epoch - 2ms/step\n",
            "Epoch 12/20\n",
            "60000/60000 - 119s - loss: 0.1357 - accuracy: 0.9734 - val_loss: 0.4478 - val_accuracy: 0.9573 - 119s/epoch - 2ms/step\n",
            "Epoch 13/20\n",
            "60000/60000 - 112s - loss: 0.1331 - accuracy: 0.9743 - val_loss: 0.4009 - val_accuracy: 0.9533 - 112s/epoch - 2ms/step\n",
            "Epoch 14/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cd1c7ff3274d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                     verbose=2, shuffle=True)\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"================================ Conf. 3 ================================ \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1713\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1244\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1247\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1248\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    676\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   4063\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4064\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 4065\u001b[0;31m         _ctx, \"Identity\", name, input)\n\u001b[0m\u001b[1;32m   4066\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4067\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 64\n",
        "BATCH_SIZE1 = 1\n",
        "BATCH_SIZE2 = 1\n",
        "BATCH_SIZE3 = 1\n",
        "BATCH_SIZE4 = 1\n",
        "BATCH_SIZE5 = 64\n",
        "\n",
        "# Load training and test datasets.\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images,\n",
        "                               test_labels) = mnist.load_data()\n",
        "\n",
        "# Standardize the data.\n",
        "mean = np.mean(train_images)\n",
        "stddev = np.std(train_images)\n",
        "train_images = (train_images - mean) / stddev\n",
        "test_images = (test_images - mean) / stddev\n",
        "\n",
        "# One-hot encode labels.\n",
        "train_labels = to_categorical(train_labels, num_classes=10)\n",
        "test_labels = to_categorical(test_labels, num_classes=10)\n",
        "\n",
        "# Create a Sequential model.\n",
        "# 784 inputs.\n",
        "# Two Dense (fully connected) layers with 25 and 10 neurons.\n",
        "# relu as activation function for hidden layer and\n",
        "# He normal initializer.\n",
        "# Softmax as activation function for output layer\n",
        "# and Glorot uniform initializer.\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(25, activation='relu',\n",
        "                       kernel_initializer='he_normal',\n",
        "                       bias_initializer='zeros'),\n",
        "    keras.layers.Dense(10, activation='softmax',\n",
        "                       kernel_initializer='glorot_uniform',\n",
        "                       bias_initializer='zeros')])\n",
        "\n",
        "initializer = keras.initializers.RandomUniform(\n",
        "    minval=-0.1, maxval=0.1)\n",
        "\n",
        "model1 = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(25, activation='tanh',\n",
        "                       kernel_initializer=initializer,\n",
        "                       bias_initializer='zeros'),\n",
        "    keras.layers.Dense(10, activation='sigmoid',\n",
        "                       kernel_initializer=initializer,\n",
        "                       bias_initializer='zeros')])\n",
        "\n",
        "model2 = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(25, activation='tanh',\n",
        "                       kernel_initializer=initializer,\n",
        "                       bias_initializer='zeros'),\n",
        "    keras.layers.Dense(10, activation='sigmoid',\n",
        "                       kernel_initializer=initializer,\n",
        "                       bias_initializer='zeros')])\n",
        "\n",
        "model3 = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(25, activation='tanh',\n",
        "                       kernel_initializer='glorot_uniform',\n",
        "                       bias_initializer='zeros'),\n",
        "    keras.layers.Dense(10, activation='sigmoid',\n",
        "                       kernel_initializer='glorot_uniform',\n",
        "                       bias_initializer='zeros')])\n",
        "\n",
        "model4 = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(25, activation='relu',\n",
        "                       kernel_initializer='he_normal',\n",
        "                       bias_initializer='zeros'),\n",
        "    keras.layers.Dense(10, activation='softmax',\n",
        "                       kernel_initializer='glorot_uniform',\n",
        "                       bias_initializer='zeros')])\n",
        "\n",
        "model5 = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(25, activation='relu',\n",
        "                       kernel_initializer='he_normal',\n",
        "                       bias_initializer='zeros'),\n",
        "    keras.layers.Dense(10, activation='softmax',\n",
        "                       kernel_initializer='glorot_uniform',\n",
        "                       bias_initializer='zeros')])\n",
        "\n",
        "# Use Adam optimizer with default parameters.\n",
        "# Categorical cross-entropy as loss function and\n",
        "# report accuracy during training.\n",
        "\n",
        "opt1 = keras.optimizers.SGD(learning_rate=0.01)\n",
        "opt2 = keras.optimizers.SGD(learning_rate=10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics =['accuracy'])\n",
        "\n",
        "model1.compile(loss='mean_squared_error', \n",
        "               optimizer = opt1, \n",
        "               metrics =['accuracy'])\n",
        "\n",
        "model2.compile(loss='mean_squared_error',\n",
        "              optimizer = opt2,\n",
        "              metrics =['accuracy'])\n",
        "\n",
        "model3.compile(loss='mean_squared_error',\n",
        "              optimizer = 'adam',\n",
        "              metrics =['accuracy'])\n",
        "\n",
        "model4.compile(loss='categorical_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics =['accuracy'])\n",
        "\n",
        "model5.compile(loss='categorical_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics =['accuracy'])\n",
        "\n",
        "# Train the model for 20 epochs.\n",
        "# Shuffle (randomize) order.\n",
        "# Update weights after 64 examples (batch_size=64).\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "                    verbose=2, shuffle=True)\n",
        "\n",
        "print(\"================================ Conf. 1 ================================ \")\n",
        "\n",
        "history1 = model.fit(train_images, train_labels,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    epochs=EPOCHS, batch_size=BATCH_SIZE1,\n",
        "                    verbose=2, shuffle=True)\n",
        "\n",
        "print(\"================================ Conf. 2 ================================ \")\n",
        "\n",
        "history2 = model.fit(train_images, train_labels,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    epochs=EPOCHS, batch_size=BATCH_SIZE2,\n",
        "                    verbose=2, shuffle=True)\n",
        "\n",
        "print(\"================================ Conf. 3 ================================ \")\n",
        "\n",
        "history3 = model.fit(train_images, train_labels,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    epochs=EPOCHS, batch_size=BATCH_SIZE3,\n",
        "                    verbose=2, shuffle=True)\n",
        "\n",
        "print(\"================================ Conf. 4 ================================ \")\n",
        "\n",
        "history4 = model.fit(train_images, train_labels,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    epochs=EPOCHS, batch_size=BATCH_SIZE4,\n",
        "                    verbose=2, shuffle=True)\n",
        "\n",
        "print(\"================================ Conf. 5 ================================ \")\n",
        "\n",
        "history5 = model.fit(train_images, train_labels,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    epochs=EPOCHS, batch_size=BATCH_SIZE5,\n",
        "                    verbose=2, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(1.0 - np.array(history.history['accuracy']))\n",
        "plt.plot(1.0 - np.array(history.history['val_accuracy']))\n",
        "plt.title('Comparison between training error and test error')\n",
        "plt.ylabel('error')\n",
        "plt.xlabel('training epoch')\n",
        "plt.xlim(0,20)\n",
        "plt.legend(['train error', 'test error'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(1.0 - np.array(history1.history['accuracy']))\n",
        "plt.plot(1.0 - np.array(history1.history['val_accuracy']))\n",
        "plt.title('Comparison between training error and test error')\n",
        "plt.ylabel('error')\n",
        "plt.xlabel('training epoch')\n",
        "plt.xlim(0,20)\n",
        "plt.legend(['train error', 'test error'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(1.0 - np.array(history2.history['accuracy']))\n",
        "plt.plot(1.0 - np.array(history2.history['val_accuracy']))\n",
        "plt.title('Comparison between training error and test error')\n",
        "plt.ylabel('error')\n",
        "plt.xlabel('training epoch')\n",
        "plt.xlim(0,20)\n",
        "plt.legend(['train error', 'test error'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(1.0 - np.array(history3.history['accuracy']))\n",
        "plt.plot(1.0 - np.array(history3.history['val_accuracy']))\n",
        "plt.title('Comparison between training error and test error')\n",
        "plt.ylabel('error')\n",
        "plt.xlabel('training epoch')\n",
        "plt.xlim(0,20)\n",
        "plt.legend(['train error', 'test error'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(1.0 - np.array(history4.history['accuracy']))\n",
        "plt.plot(1.0 - np.array(history4.history['val_accuracy']))\n",
        "plt.title('Comparison between training error and test error')\n",
        "plt.ylabel('error')\n",
        "plt.xlabel('training epoch')\n",
        "plt.xlim(0,20)\n",
        "plt.legend(['train error', 'test error'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(1.0 - np.array(history5.history['accuracy']))\n",
        "plt.plot(1.0 - np.array(history5.history['val_accuracy']))\n",
        "plt.title('Comparison between training error and test error')\n",
        "plt.ylabel('error')\n",
        "plt.xlabel('training epoch')\n",
        "plt.xlim(0,20)\n",
        "plt.legend(['train error', 'test error'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yqEyiY5bWhT7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}