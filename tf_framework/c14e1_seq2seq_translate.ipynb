{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnitnaw/LDL/blob/main/tf_framework/c14e1_seq2seq_translate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_gzUAzwlkxeb",
        "outputId": "811e520e-3a20-4fef-e726-d9f3c9a54c96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe MIT License (MIT)\\nCopyright (c) 2021 NVIDIA\\nPermission is hereby granted, free of charge, to any person obtaining a copy of\\nthis software and associated documentation files (the \"Software\"), to deal in\\nthe Software without restriction, including without limitation the rights to\\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\\nthe Software, and to permit persons to whom the Software is furnished to do so,\\nsubject to the following conditions:\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "The MIT License (MIT)\n",
        "Copyright (c) 2021 NVIDIA\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
        "this software and associated documentation files (the \"Software\"), to deal in\n",
        "the Software without restriction, including without limitation the rights to\n",
        "use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
        "the Software, and to permit persons to whom the Software is furnished to do so,\n",
        "subject to the following conditions:\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
        "FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
        "COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
        "IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
        "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X30tNBFikxec"
      },
      "source": [
        "This code example demonstrates how to build a neural machine translation network. It is a sequence-to-sequence network based on an encoder-decoder architecture. More context for this code example can be found in the section \"Programming Example: Neural Machine Translation\" in Chapter 14 in the book Learning Deep Learning by Magnus Ekman (ISBN: 9780137470358).\n",
        "\n",
        "The data used to train the model is expected to be in the file ../data/fra.txt.\n",
        "We begin by importing modules that we need for the program."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive"
      ],
      "metadata": {
        "id": "1xGfChqplfRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_head = '/content/drive/MyDrive/Colab Notebooks/' # You have to change this. "
      ],
      "metadata": {
        "id": "gTjnUp3jlhFG",
        "outputId": "f7b00eaa-c850-4bc1-d51d-4e2d11a0531f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VK1ObZX6kxed"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text \\\n",
        "    import text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence \\\n",
        "    import pad_sequences\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBXRzudGkxee"
      },
      "source": [
        "Next, we define some constants. We specify a vocabulary size of 10,000 symbols, out of which four indices are reserved for padding, out-of-vocabulary words (denoted as UNK), START tokens, and STOP tokens. Our training corpus is large, so we set the parameter READ_LINES to the number of lines in the input file we want to use in our example (60,000). Our layers consist of 256 units (LAYER_SIZE), and the embedding layers output 128 dimensions (EMBEDDING_WIDTH). We use 20% (TEST_PERCENT) of the dataset as test set and further select 20 sentences (SAMPLE_SIZE) to inspect in detail during training. We limit the length of the source and destination sentences to, at most, 60 words (MAX_LENGTH). Finally, we provide the path to the data file, where each line is expected to contain two versions of the same sentence (one in each language) separated by a tab character."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4d7m6nCskxef"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "MAX_WORDS = 10000\n",
        "READ_LINES = 60000\n",
        "LAYER_SIZE = 256\n",
        "EMBEDDING_WIDTH = 128\n",
        "TEST_PERCENT = 0.2\n",
        "SAMPLE_SIZE = 20\n",
        "OOV_WORD = 'UNK'\n",
        "PAD_INDEX = 0\n",
        "OOV_INDEX = 1\n",
        "START_INDEX = MAX_WORDS - 2\n",
        "STOP_INDEX = MAX_WORDS - 1\n",
        "MAX_LENGTH = 60\n",
        "#SRC_DEST_FILE_NAME = '../data/fra.txt'\n",
        "SRC_DEST_FILE_NAME = path_head+'data/fra.txt'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSAlmknJkxef"
      },
      "source": [
        "The next code snippet shows the function used to read the input data file and do some initial processing. Each line is split into two strings, where the first contains the sentence in the destination language and the second contains the sentence in the source language. We use the function text_to_word_sequence() to clean the data somewhat (make everything lowercase and remove punctuation) and split each sentence into a list of individual words. If the list (sentence) is longer than the maximum allowed length, then it is truncated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PEP4AKJbkxeg"
      },
      "outputs": [],
      "source": [
        "# Function to read file.\n",
        "def read_file_combined(file_name, max_len):\n",
        "    file = open(file_name, 'r', encoding='utf-8')\n",
        "    src_word_sequences = []\n",
        "    dest_word_sequences = []\n",
        "    for i, line in enumerate(file):\n",
        "        if i == READ_LINES:\n",
        "            break\n",
        "        pair = line.split('\\t')\n",
        "        word_sequence = text_to_word_sequence(pair[1])\n",
        "        src_word_sequence = word_sequence[0:max_len]\n",
        "        src_word_sequences.append(src_word_sequence)\n",
        "        word_sequence = text_to_word_sequence(pair[0])\n",
        "        dest_word_sequence = word_sequence[0:max_len]\n",
        "        dest_word_sequences.append(dest_word_sequence)\n",
        "    file.close()\n",
        "    return src_word_sequences, dest_word_sequences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8-PqUX7kxeg"
      },
      "source": [
        "The next code snippet shows functions used to turn sequences of words into\n",
        "sequences of tokens, and vice versa. We call tokenize() a single time for each\n",
        "language, so the argument sequences is a list of lists where each of the inner\n",
        "lists represents a sentence. The Tokenizer class assigns indices to the most\n",
        "common words and returns either these indices or the reserved OOV_INDEX\n",
        "for less common words that did not make it into the vocabulary. We tell the\n",
        "Tokenizer to use a vocabulary of 9998 (MAX_WORDS-2)—that is, use only\n",
        "indices 0 to 9997, so that we can use indices 9998 and 9999 as our START and\n",
        "STOP tokens (the Tokenizer does not support the notion of START and STOP\n",
        "tokens but does reserve index 0 to use as a padding token and index 1 for outof-\n",
        "vocabulary words). Our tokenize() function returns both the tokenized\n",
        "sequence and the Tokenizer object itself. This object will be needed anytime we\n",
        "want to convert tokens back into words.\n",
        "\n",
        "The function tokens_to_words() requires a Tokenizer and a list of indices. We simply check for the reserved indices: If we find a match, we replace them with hardcoded strings, and if we find no match, we let the Tokenizer convert the index to the corresponding word string. The Tokenizer expects a list of lists of indices and returns a list of strings, which is why we need to call it with [[index]] and then select the 0th element to arrive at a string.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gTJbbKx5kxeh"
      },
      "outputs": [],
      "source": [
        "# Functions to tokenize and un-tokenize sequences.\n",
        "def tokenize(sequences):\n",
        "    # \"MAX_WORDS-2\" used to reserve two indices\n",
        "    # for START and STOP.\n",
        "    tokenizer = Tokenizer(num_words=MAX_WORDS-2,\n",
        "                          oov_token=OOV_WORD)\n",
        "    tokenizer.fit_on_texts(sequences)\n",
        "    token_sequences = tokenizer.texts_to_sequences(sequences)\n",
        "    return tokenizer, token_sequences\n",
        "\n",
        "def tokens_to_words(tokenizer, seq):\n",
        "    word_seq = []\n",
        "    for index in seq:\n",
        "        if index == PAD_INDEX:\n",
        "            word_seq.append('PAD')\n",
        "        elif index == OOV_INDEX:\n",
        "            word_seq.append(OOV_WORD)\n",
        "        elif index == START_INDEX:\n",
        "            word_seq.append('START')\n",
        "        elif index == STOP_INDEX:\n",
        "            word_seq.append('STOP')\n",
        "        else:\n",
        "            word_seq.append(tokenizer.sequences_to_texts(\n",
        "                [[index]])[0])\n",
        "    print(word_seq)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcbO6FGjkxei"
      },
      "source": [
        "Given these helper functions, it is trivial to read the input data\n",
        "file and convert into tokenized sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z9fQ5-kikxei"
      },
      "outputs": [],
      "source": [
        "# Read file and tokenize.\n",
        "src_seq, dest_seq = read_file_combined(SRC_DEST_FILE_NAME,\n",
        "                                       MAX_LENGTH)\n",
        "src_tokenizer, src_token_seq = tokenize(src_seq)\n",
        "dest_tokenizer, dest_token_seq = tokenize(dest_seq)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWYKtqeQkxej"
      },
      "source": [
        "It is now time to arrange the data into tensors that can be used for training and testing. See the book for more details about the desired format. The code snippet below shows a compact way of creating the three arrays that we need. The first two lines create two new lists, each containing the destination sequences but the first (dest_target_token_seq) also augmented with STOP_INDEX after each sequence and the second (dest_input_token_seq) augmented with both START_INDEX and STOP_INDEX. It is easy to miss that dest_input_token_seq has a STOP_INDEX, but that falls out naturally because it is created from the dest_target_token_seq for which a STOP_INDEX was just added to each sentence.\n",
        "\n",
        "Next, we call pad_sequences() on both the original src_input_data list (of lists) and on these two new destination lists. The pad_sequences() function pads the sequences with the PAD value and then returns a NumPy array. The default behavior of pad_sequences is to do prepadding, and we do that for the source sequence but explicitly ask for postpadding for the destination sequences.\n",
        "\n",
        "You might wonder why there is no call to to_categorical() in the statement that creates the target (output) data. We are used to wanting to have the ground truth one-hot encoded for textual data. Not doing so is an optimization to avoid wasting too much memory. With a vocabulary of 10,000 words, and 60,000 training examples, where each training example is a sentence, the memory footprint of the one-hot encoded data starts becoming a problem. Therefore, instead of one-hot encoding all data up front, there is a way to let Keras deal with that in the loss function itself.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nWEEw4tqkxej"
      },
      "outputs": [],
      "source": [
        "# Prepare training data.\n",
        "dest_target_token_seq = [x + [STOP_INDEX] for x in dest_token_seq]\n",
        "dest_input_token_seq = [[START_INDEX] + x for x in\n",
        "                        dest_target_token_seq]\n",
        "src_input_data = pad_sequences(src_token_seq)\n",
        "dest_input_data = pad_sequences(dest_input_token_seq,\n",
        "                                padding='post')\n",
        "dest_target_data = pad_sequences(\n",
        "    dest_target_token_seq, padding='post', maxlen\n",
        "    = len(dest_input_data[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCYBPappkxej"
      },
      "source": [
        "The next code snippet demonstrates how we can manually split our dataset into a training dataset and a test dataset. In previous examples, we either relied on datasets that are already split this way or we used functionality inside of Keras when calling the fit() function. However, in this case, we want some more control ourselves because we will want to inspect a few select members of the test set in detail. We split the dataset by first creating a list test_indices, which contains a 20% (TEST_PERCENT) subset of all the numbers from 0 to N−1, where N is the size of our original dataset. We then create a list train_indices, which contains the remaining 80%. We can now use these lists to select a number of rows in the matrices representing the dataset and create two new collections of matrices, one to be used as training set and one to be used as test set. Finally, we create a third collection of matrices, which only contains 20 (SAMPLE_SIZE) random examples from the test dataset. We will use them to inspect the resulting translations in detail, but since that is a manual process, we limit ourselves to a small number of sentences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EgxKf95Ukxek"
      },
      "outputs": [],
      "source": [
        "# Split into training and test set.\n",
        "rows = len(src_input_data[:,0])\n",
        "all_indices = list(range(rows))\n",
        "test_rows = int(rows * TEST_PERCENT)\n",
        "test_indices = random.sample(all_indices, test_rows)\n",
        "train_indices = [x for x in all_indices if x not in test_indices]\n",
        "\n",
        "train_src_input_data = src_input_data[train_indices]\n",
        "train_dest_input_data = dest_input_data[train_indices]\n",
        "train_dest_target_data = dest_target_data[train_indices]\n",
        "\n",
        "test_src_input_data = src_input_data[test_indices]\n",
        "test_dest_input_data = dest_input_data[test_indices]\n",
        "test_dest_target_data = dest_target_data[test_indices]\n",
        "\n",
        "# Create a sample of the test set that we will inspect in detail.\n",
        "test_indices = list(range(test_rows))\n",
        "sample_indices = random.sample(test_indices, SAMPLE_SIZE)\n",
        "sample_input_data = test_src_input_data[sample_indices]\n",
        "sample_target_data = test_dest_target_data[sample_indices]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_blD-fg1kxek"
      },
      "source": [
        "We are now ready to build our model. It consists of an encoder part and a decoder part (see detailed figures in the book). The encoder consists of an embedding layer and two LSTM layers. The decoder consists of an embedding layer, two LSTM layers, and a fully connected softmax layer. We define these as two separate models, which we later tie together. Four noteworthy outputs are the state outputs from the two encoder LSTM layers. These are used as inputs into the decoder LSTM layers to communicate the accumulated state from the encoder to the decoder. To be able to express this complex model we need to use the Keras Functional API.\n",
        "\n",
        "The code snippet below contains the implementation of the encoder model. There are a few things worth pointing out. Because we are interested in accessing the internal state of the LSTM layers, we need to provide the argument return_state=True. This argument instructs the LSTM object to return not only a variable representing the layer’s output but also variables representing the c and h states. Further, for a recurrent layer that feeds another recurrent layer, we need to provide the argument return_sequences=True so that the subsequent layer sees the outputs of each timestep. This is also true for the final recurrent layer if we want the network to produce an output during each timestep. For our encoder, we are only interested in the final state, so we do not set return_sequences to True for enc_layer2.\n",
        "\n",
        "Once all layers are connected, we create the actual model by calling the Model() constructor and providing arguments to specify what inputs and outputs will be external to the model. The model takes the source sentence as input and produces the internal states of the two LSTM layers as outputs. Each LSTM layer has both an h state and c state, so in total, the model will output four state variables as output. Each state variable is in itself a tensor consisting of multiple values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Fp3OL5lhkxek",
        "outputId": "49163509-a5a5-470b-a44c-6cf1e72e6177",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 128)         1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 [(None, None, 256),       394240    \n",
            "                              (None, 256),                       \n",
            "                              (None, 256)]                       \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               [(None, 256),             525312    \n",
            "                              (None, 256),                       \n",
            "                              (None, 256)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,199,552\n",
            "Trainable params: 2,199,552\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build encoder model.\n",
        "# Input is input sequence in source language.\n",
        "enc_embedding_input = Input(shape=(None, ))\n",
        "\n",
        "# Create the encoder layers.\n",
        "enc_embedding_layer = Embedding(\n",
        "    output_dim=EMBEDDING_WIDTH, input_dim\n",
        "    = MAX_WORDS, mask_zero=True)\n",
        "enc_layer1 = LSTM(LAYER_SIZE, return_state=True,\n",
        "                  return_sequences=True)\n",
        "enc_layer2 = LSTM(LAYER_SIZE, return_state=True)\n",
        "\n",
        "# Connect the encoder layers.\n",
        "# We don't use the last layer output, only the state.\n",
        "enc_embedding_layer_outputs = \\\n",
        "    enc_embedding_layer(enc_embedding_input)\n",
        "enc_layer1_outputs, enc_layer1_state_h, enc_layer1_state_c = \\\n",
        "    enc_layer1(enc_embedding_layer_outputs)\n",
        "_, enc_layer2_state_h, enc_layer2_state_c = \\\n",
        "    enc_layer2(enc_layer1_outputs)\n",
        "\n",
        "# Build the model.\n",
        "enc_model = Model(enc_embedding_input,\n",
        "                  [enc_layer1_state_h, enc_layer1_state_c,\n",
        "                   enc_layer2_state_h, enc_layer2_state_c])\n",
        "enc_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5oGjMg6kxel"
      },
      "source": [
        "The next code snippet shows the implementation of the decoder model. In addition to the sentence in the destination language, it takes the output state from the encoder model as inputs. We initialize the decoder LSTM layers (using the argument initial_state) with this state at the first timestep.\n",
        "\n",
        "For the decoder, we do want the top LSTM layer to produce an output for each timestep (the decoder should create a full sentence and not just a final state), so we set return_sequences=True for both LSTM layers.\n",
        "\n",
        "We create the model by calling the Model() constructor. The inputs consist of the destination sentence (time shifted by one timestep) and initial state for the LSTM layers. As we soon will see, when using the model for inference, we need to explicitly manage the internal state for the decoder. Therefore, we declare the states as outputs of the model in addition to the softmax output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gplzkreGkxel",
        "outputId": "59ea5d8a-02b4-4517-e3c3-01adef2ac55e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 128)    1280000     ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, None, 256),  394240      ['embedding_1[0][0]',            \n",
            "                                 (None, 256),                     'input_2[0][0]',                \n",
            "                                 (None, 256)]                     'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 256),  525312      ['lstm_2[0][0]',                 \n",
            "                                 (None, 256),                     'input_4[0][0]',                \n",
            "                                 (None, 256)]                     'input_5[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 10000)  2570000     ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,769,552\n",
            "Trainable params: 4,769,552\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build decoder model.\n",
        "# Input to the network is input sequence in destination\n",
        "# language and intermediate state.\n",
        "dec_layer1_state_input_h = Input(shape=(LAYER_SIZE,))\n",
        "dec_layer1_state_input_c = Input(shape=(LAYER_SIZE,))\n",
        "dec_layer2_state_input_h = Input(shape=(LAYER_SIZE,))\n",
        "dec_layer2_state_input_c = Input(shape=(LAYER_SIZE,))\n",
        "dec_embedding_input = Input(shape=(None, ))\n",
        "\n",
        "# Create the decoder layers.\n",
        "dec_embedding_layer = Embedding(output_dim=EMBEDDING_WIDTH,\n",
        "                                input_dim=MAX_WORDS,\n",
        "                                mask_zero=True)\n",
        "dec_layer1 = LSTM(LAYER_SIZE, return_state = True,\n",
        "                  return_sequences=True)\n",
        "dec_layer2 = LSTM(LAYER_SIZE, return_state = True,\n",
        "                  return_sequences=True)\n",
        "dec_layer3 = Dense(MAX_WORDS, activation='softmax')\n",
        "\n",
        "# Connect the decoder layers.\n",
        "dec_embedding_layer_outputs = dec_embedding_layer(\n",
        "    dec_embedding_input)\n",
        "dec_layer1_outputs, dec_layer1_state_h, dec_layer1_state_c = \\\n",
        "    dec_layer1(dec_embedding_layer_outputs,\n",
        "    initial_state=[dec_layer1_state_input_h,\n",
        "                   dec_layer1_state_input_c])\n",
        "dec_layer2_outputs, dec_layer2_state_h, dec_layer2_state_c = \\\n",
        "    dec_layer2(dec_layer1_outputs,\n",
        "    initial_state=[dec_layer2_state_input_h,\n",
        "                   dec_layer2_state_input_c])\n",
        "dec_layer3_outputs = dec_layer3(dec_layer2_outputs)\n",
        "\n",
        "# Build the model.\n",
        "dec_model = Model([dec_embedding_input,\n",
        "                   dec_layer1_state_input_h,\n",
        "                   dec_layer1_state_input_c,\n",
        "                   dec_layer2_state_input_h,\n",
        "                   dec_layer2_state_input_c],\n",
        "                  [dec_layer3_outputs, dec_layer1_state_h,\n",
        "                   dec_layer1_state_c, dec_layer2_state_h,\n",
        "                   dec_layer2_state_c])\n",
        "dec_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYUPU_b6kxel"
      },
      "source": [
        "The next code snippet connects the two models to build a full encoder-decoder network. We decided to use RMSProp as optimizer because some experiments indicate that it performs better than Adam for this specific model. We use sparse_categorical_crossentropy instead of the normal categorical_crossentropy as loss function because we have not one-hot encoded the output data.\n",
        "\n",
        "Even after connecting the encoder and decoder model to form a joint model, they can both still be used in isolation. If we train the joint model, it will update the weights of the first two models. This is useful because, when we do inference, we want an encoder model that is decoupled from the decoder model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qj7O8ZDYkxel",
        "outputId": "2d4934b6-c847-476f-a4bf-6ee0cdb6a99e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " model (Functional)             [(None, 256),        2199552     ['input_7[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " model_1 (Functional)           [(None, None, 10000  4769552     ['input_8[0][0]',                \n",
            "                                ),                                'model[0][0]',                  \n",
            "                                 (None, 256),                     'model[0][1]',                  \n",
            "                                 (None, 256),                     'model[0][2]',                  \n",
            "                                 (None, 256),                     'model[0][3]']                  \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,969,104\n",
            "Trainable params: 6,969,104\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build and compile full training model.\n",
        "# We do not use the state output when training.\n",
        "train_enc_embedding_input = Input(shape=(None, ))\n",
        "train_dec_embedding_input = Input(shape=(None, ))\n",
        "intermediate_state = enc_model(train_enc_embedding_input)\n",
        "train_dec_output, _, _, _, _ = dec_model(\n",
        "    [train_dec_embedding_input] +\n",
        "    intermediate_state)\n",
        "training_model = Model([train_enc_embedding_input,\n",
        "                        train_dec_embedding_input],\n",
        "                        train_dec_output)\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "training_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                       optimizer=optimizer, metrics =['accuracy'])\n",
        "training_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRzlnSehkxem"
      },
      "source": [
        "The final code snippet shows hos to train and test the model. We take a slightly different approach than in previous examples. In previous examples, we instructed fit() to train for multiple epochs, and then we studied the results and ended our program. In this example, we create our own training loop where we instruct fit() to train for only a single epoch at a time. We then use our model to create some predictions before going back and training for another epoch. This approach enables some detailed evaluation of just a small set of samples after each epoch.\n",
        "\n",
        "Most of the code sequence is the loop used to create translations for the smaller set of samples that we created from the test dataset. This piece of code consists of a loop that iterates over all the examples in sample_input_data. We provide the source sentence to the encoder model to create the resulting internal state and store to the variable last_states. We also initialize the variable prev_word_index with the index corresponding to the START symbol. We then enter the innermost loop and predict a single word using the decoder model. We also read out the internal state. This data is then used as input to the decoder model in the next iteration, and we iterate until the model produces a STOP token or until a given number of words have been produced. Finally, we convert the produced tokenized sequences into the corresponding word sequences and print them out.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wEZLZIVbkxem",
        "outputId": "9cd564c4-eaa8-4637-c487-1adf9b9c3885",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step:  0\n",
            "375/375 [==============================] - 60s 114ms/step - loss: 4.6916 - accuracy: 0.2631 - val_loss: 4.2905 - val_accuracy: 0.2698\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'you', 'you', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'you', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'is', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'is', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'you', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'is', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'is', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'is', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'you', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'is', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'you', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'you', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'is', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'you', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'you', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  1\n",
            "375/375 [==============================] - 27s 72ms/step - loss: 4.0406 - accuracy: 0.3599 - val_loss: 3.8879 - val_accuracy: 0.4027\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'not', 'to', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'you', 'to', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'you', 'to', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'you', 'to', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'you', 'to', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'you', 'the', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'i', 'to', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'you', 'to', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'is', 'to', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'i', 'to', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'you', 'the', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'i', 'to', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  2\n",
            "375/375 [==============================] - 27s 71ms/step - loss: 3.7700 - accuracy: 0.4186 - val_loss: 3.6751 - val_accuracy: 0.4300\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'know', 'you', 'a', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'not', 'a', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'was', 'a', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'is', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'know', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'is', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'was', 'a', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'is', 'the', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'is', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'know', 'i', 'a', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'is', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  3\n",
            "375/375 [==============================] - 28s 74ms/step - loss: 3.5669 - accuracy: 0.4378 - val_loss: 3.4995 - val_accuracy: 0.4435\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'think', 'i', 'a', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'a', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'is', 'a', 'the', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'think', 'you', 'a', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'are', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['it', 'is', 'a', 'a', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'a', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'know', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['they', 'are', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'are', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'think', 'i', 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'are', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'is', 'a', 'a', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  4\n",
            "375/375 [==============================] - 27s 72ms/step - loss: 3.3910 - accuracy: 0.4574 - val_loss: 3.3287 - val_accuracy: 0.4730\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'can', 'you', 'a', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", \"can't\", 'to', 'the', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'have', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"can't\", 'to', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'are', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'was', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'have', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'very', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'are', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"can't\", 'to', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"we're\", 'not', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'are', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'have', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  5\n",
            "375/375 [==============================] - 27s 72ms/step - loss: 3.2268 - accuracy: 0.4854 - val_loss: 3.1860 - val_accuracy: 0.4997\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'want', 'to', 'do', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'a', 'good', 'job', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", \"don't\", 'be', 'the', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'have', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'know', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'are', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['the', 'love', 'is', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'is', 'a', 'good', 'job', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'want', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'all', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'are', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'not', 'a', 'new', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'were', 'to', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'are', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['the', 'were', 'is', 'the', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  6\n",
            "375/375 [==============================] - 27s 72ms/step - loss: 3.0677 - accuracy: 0.5076 - val_loss: 3.0325 - val_accuracy: 0.5137\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'need', 'to', 'do', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['this', 'is', 'to', 'the', 'job', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", \"don't\", 'be', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', \"can't\", 'do', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"can't\", 'know', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'the', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'is', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['what', 'me', 'you', 'a', 'job', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'feel', 'like', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'all', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'very', 'happy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'not', 'a', 'be', 'job', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'have', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'very', 'happy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"where's\", 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  7\n",
            "375/375 [==============================] - 27s 72ms/step - loss: 2.9168 - accuracy: 0.5241 - val_loss: 2.9115 - val_accuracy: 0.5295\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'need', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['he', 'is', 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", \"don't\", 'be', 'a', 'money', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'friend', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', \"can't\", 'do', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'have', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'the', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'get', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['is', 'a', 'do', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'never', 'be', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'hate', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'all', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'so', 'happy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'not', 'the', 'friend', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'have', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'so', 'happy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['please', 'is', 'the', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  8\n",
            "375/375 [==============================] - 28s 75ms/step - loss: 2.7786 - accuracy: 0.5400 - val_loss: 2.7701 - val_accuracy: 0.5459\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'need', 'to', 'go', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"what's\", 'it', 'the', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", \"don't\", 'go', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'friend', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', \"can't\", 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'know', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'ready', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'in', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['get', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['do', 'you', 'need', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'has', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'hate', 'the', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'all', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'very', 'busy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'in', 'the', 'friend', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"we're\", 'not', 'happy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'very', 'busy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"where's\", 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  9\n",
            "375/375 [==============================] - 28s 74ms/step - loss: 2.6522 - accuracy: 0.5557 - val_loss: 2.6793 - val_accuracy: 0.5581\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['can', 'i', 'need', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'no', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"what's\", 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", \"don't\", 'be', 'me', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'the', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', \"can't\", 'go', 'to', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'be', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'still', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'the', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['come', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['do', 'you', 'like', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'never', 'be', 'happy', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'feel', 'the', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'not', 'all', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'glad', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'have', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"where's\", 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  10\n",
            "375/375 [==============================] - 28s 74ms/step - loss: 2.5382 - accuracy: 0.5700 - val_loss: 2.5657 - val_accuracy: 0.5712\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['can', 'i', 'need', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'no', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"what's\", 'that', 'is', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", 'go', 'to', 'be', 'a', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'good', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'can', 'go', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'think', 'tom', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'still', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'lot', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['get', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['do', 'you', 'do', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'to', 'be', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'hate', 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'too', 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'have', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'too', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"where's\", 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  11\n",
            "375/375 [==============================] - 28s 75ms/step - loss: 2.4315 - accuracy: 0.5837 - val_loss: 2.4769 - val_accuracy: 0.5843\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['did', 'i', 'need', 'to', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'no', 'problem', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"what's\", 'that', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", 'make', 'me', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'a', 'problem', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'problem', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'can', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"don't\", 'know', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'still', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'problem', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['get', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['do', 'you', 'do', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'kept', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'hate', 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'to', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'in', 'the', 'new', 'way', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'have', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"where's\", 'the', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  12\n",
            "375/375 [==============================] - 28s 75ms/step - loss: 2.3310 - accuracy: 0.5974 - val_loss: 2.3931 - val_accuracy: 0.5956\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['did', 'i', 'need', 'to', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'no', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"what's\", 'there', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", 'tell', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'can', 'go', 'now', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'know', 'tom', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'still', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['go', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['do', 'you', 'do', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'did', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'hate', 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'all', 'us', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'in', 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'have', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'very', 'funny', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"where's\", 'the', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  13\n",
            "375/375 [==============================] - 29s 77ms/step - loss: 2.2351 - accuracy: 0.6109 - val_loss: 2.3171 - val_accuracy: 0.6059\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['can', 'i', 'get', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'in', 'the', 'house', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"what's\", 'there', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", 'tell', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'my', 'friend', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'in', 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'can', 'go', 'now', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"can't\", 'go', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'still', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'do', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['do', 'you', 'do', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'came', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'hate', 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'too', 'tired', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'have', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"where's\", 'the', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  14\n",
            "375/375 [==============================] - 28s 76ms/step - loss: 2.1437 - accuracy: 0.6233 - val_loss: 2.2554 - val_accuracy: 0.6151\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['can', 'i', 'get', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'three', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"what's\", 'there', 'here', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", 'make', 'me', 'get', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'my', 'friend', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'problem', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'can', 'go', 'now', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', \"can't\", 'go', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'still', 'still', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'work', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'like', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'kept', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'hate', 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'us', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'too', 'tired', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'have', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"where's\", 'the', 'room', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  15\n",
            "375/375 [==============================] - 28s 75ms/step - loss: 2.0578 - accuracy: 0.6350 - val_loss: 2.1840 - val_accuracy: 0.6252\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['can', 'i', 'get', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'went', 'in', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"what's\", 'the', 'door', 'now', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", 'make', 'me', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'my', 'friend', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'problem', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'can', 'go', 'now', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'know', 'what', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'still', 'still', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'go', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'like', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'kept', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'hate', 'the', 'job', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'for', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'proud', 'of', 'the', 'way', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'know', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'awesome', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"where's\", 'the', 'house', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  16\n",
            "375/375 [==============================] - 29s 78ms/step - loss: 1.9753 - accuracy: 0.6463 - val_loss: 2.1105 - val_accuracy: 0.6342\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['can', 'i', 'see', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'likes', 'the', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"what's\", 'in', 'the', 'door', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", 'talk', 'at', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'my', 'friend', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'can', 'go', 'now', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'know', 'what', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'still', 'still', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'work', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'like', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'kept', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'hate', 'the', 'best', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'all', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'went', 'in', 'a', 'same', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'have', 'us', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'very', 'wise', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"where's\", 'the', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  17\n",
            "375/375 [==============================] - 30s 79ms/step - loss: 1.8976 - accuracy: 0.6573 - val_loss: 2.0516 - val_accuracy: 0.6443\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['can', 'i', 'see', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'has', 'his', 'money', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"what's\", 'there', 'in', 'work', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", 'tell', 'me', 'at', 'us', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'my', 'friend', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'in', 'the', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'may', 'go', 'now', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'know', 'what', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'still', 'still', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'work', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['do', 'you', 'get', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'kept', 'to', 'come', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'hate', 'the', 'best', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'dead', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'safe', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'sick', 'of', 'the', 'same', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'have', 'us', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'very', 'rude', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"where's\", 'the', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  18\n",
            "375/375 [==============================] - 29s 77ms/step - loss: 1.8223 - accuracy: 0.6681 - val_loss: 1.9971 - val_accuracy: 0.6487\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['can', 'i', 'get', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'died', 'in', 'his', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"what's\", 'in', 'the', 'house', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", 'tell', 'me', 'at', 'us', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'my', 'friend', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'in', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'should', 'go', 'now', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'know', 'what', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'still', 'still', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'work', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'going', 'of', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'kept', 'to', 'die', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'hate', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'dead', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'in', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'in', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['we', 'have', 'us', 'soon', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'important', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"where's\", 'the', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "step:  19\n",
            "375/375 [==============================] - 31s 83ms/step - loss: 1.7496 - accuracy: 0.6782 - val_loss: 1.9340 - val_accuracy: 0.6598\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'que', 'je', 'peux', 'te', 'parler\\u202f']\n",
            "['can', 'i', 'speak', 'with', 'you', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['can', 'i', 'see', 'you', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'arrivé', 'lundi']\n",
            "['tom', 'got', 'here', 'on', 'monday', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'went', 'in', 'his', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', \"qu'y\", 'a', 't', 'il', 'là', 'dedans']\n",
            "[\"what's\", 'in', 'there', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"what's\", 'there', 'in', 'school', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'ne', 'dites', 'pas', 'de', 'telles', 'choses']\n",
            "[\"don't\", 'say', 'such', 'things', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"don't\", 'tell', 'me', 'well', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'est', 'son', 'amie']\n",
            "['she', 'is', 'his', 'friend', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'is', 'my', 'friend', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'en', 'plein', 'UNK']\n",
            "['tom', 'is', 'delirious', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'in', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'vous', 'devriez', 'y', 'aller', 'maintenant']\n",
            "['you', 'should', 'go', 'now', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['you', 'should', 'go', 'now', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'ferais', 'mieux', \"d'y\", 'aller']\n",
            "[\"i'd\", 'better', 'go', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'know', 'what', 'to', 'go', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'êtes', 'vous', 'encore', 'endormie']\n",
            "['are', 'you', 'still', 'sleepy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'still', 'still', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tom', 'est', 'UNK']\n",
            "['tom', 'is', 'a', 'pediatrician', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['tom', 'is', 'a', 'teacher', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'déverrouille', 'le']\n",
            "['unlock', 'it', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"let's\", 'study', 'it', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'est', 'ce', 'moi', 'que', 'vous', 'cherchez']\n",
            "['are', 'you', 'looking', 'for', 'me', 'STOP', 'PAD', 'PAD', 'PAD']\n",
            "['are', 'you', 'going', 'to', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elle', 'continua', 'à', 'parler']\n",
            "['she', 'went', 'on', 'speaking', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['she', 'kept', 'to', 'stop', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'déteste', 'le', 'karaoké']\n",
            "['i', 'hate', 'karaoke', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "['i', 'hate', 'the', 'job', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'elles', 'sont', 'toutes', 'à', 'moi']\n",
            "[\"they're\", 'all', 'mine', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"they're\", 'all', 'for', 'me', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'tenace']\n",
            "[\"you're\", 'resilient', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'out', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'je', 'suis', 'UNK', 'à', 'des', 'allergies']\n",
            "['i', 'have', 'allergies', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"i'm\", 'a', 'bit', 'one', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'nous', 'nous', 'ennuyions']\n",
            "['we', 'were', 'bored', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"we're\", 'going', 'to', 'us', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'tu', 'es', 'paresseux']\n",
            "[\"you're\", 'lazy', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"you're\", 'very', 'fun', 'STOP']\n",
            "\n",
            "\n",
            "\n",
            "['PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'où', 'est', 'le', 'journal']\n",
            "[\"where's\", 'the', 'newspaper', 'STOP', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
            "[\"where's\", 'the', 'car', 'STOP']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train and test repeatedly.\n",
        "for i in range(EPOCHS):\n",
        "    print('step: ' , i)\n",
        "    # Train model for one epoch.\n",
        "    history = training_model.fit(\n",
        "        [train_src_input_data, train_dest_input_data],\n",
        "        train_dest_target_data, validation_data=(\n",
        "            [test_src_input_data, test_dest_input_data],\n",
        "            test_dest_target_data), batch_size=BATCH_SIZE,\n",
        "        epochs=1)\n",
        "\n",
        "    # Loop through samples to see result\n",
        "    for (test_input, test_target) in zip(sample_input_data,\n",
        "                                         sample_target_data):\n",
        "        # Run a single sentence through encoder model.\n",
        "        x = np.reshape(test_input, (1, -1))\n",
        "        last_states = enc_model.predict(\n",
        "            x, verbose=0)\n",
        "        # Provide resulting state and START_INDEX as input\n",
        "        # to decoder model.\n",
        "        prev_word_index = START_INDEX\n",
        "        produced_string = ''\n",
        "        pred_seq = []\n",
        "        for j in range(MAX_LENGTH):\n",
        "            x = np.reshape(np.array(prev_word_index), (1, 1))\n",
        "            # Predict next word and capture internal state.\n",
        "            preds, dec_layer1_state_h, dec_layer1_state_c, \\\n",
        "                dec_layer2_state_h, dec_layer2_state_c = \\\n",
        "                    dec_model.predict(\n",
        "                        [x] + last_states, verbose=0)\n",
        "            last_states = [dec_layer1_state_h,\n",
        "                           dec_layer1_state_c,\n",
        "                           dec_layer2_state_h,\n",
        "                           dec_layer2_state_c]\n",
        "            # Find the most probable word.\n",
        "            prev_word_index = np.asarray(preds[0][0]).argmax()\n",
        "            pred_seq.append(prev_word_index)\n",
        "            if prev_word_index == STOP_INDEX:\n",
        "                break\n",
        "        tokens_to_words(src_tokenizer, test_input)\n",
        "        tokens_to_words(dest_tokenizer, test_target)\n",
        "        tokens_to_words(dest_tokenizer, pred_seq)\n",
        "        print('\\n\\n')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}